{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOE STADI P *operando* `.xy` background subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "March 2023\n",
    " \n",
    "Martin Aaskov Karlsen  \n",
    "Postdoc  \n",
    "Ravnsbæk Group  \n",
    "Department of Chemistry  \n",
    "Aarhus University  \n",
    "Denmark  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below has been developed to process and plot in-house *operando* \n",
    "powder x-ray diffraction data measured at the STOE STADI P diffractometer at the \n",
    "Department of Chemistry, Aarhus University, Denmark.\n",
    "\n",
    "To be able to process data, the program will need:\n",
    "\n",
    "- The will process data files placed in a folder called `data`. The files should \n",
    "be named alphanumerically to be sorted in the proper order.\n",
    "\n",
    "- A background file should be placed in a folder called `bkg`.\n",
    "\n",
    "- The raw file(s) should be placed in a folder called `raw`. \n",
    "\n",
    "The `.raw` files are needed as the acquisition/exposure time for each scan is \n",
    "extracted from the `.raw` file(s), just as the start time of the experiment is. \n",
    "The time of the last modification of the `.raw` file is used to calculate the \n",
    "duration of the experiment, as the time of the last modification corresponds to\n",
    "appending of the last scan.\n",
    "\n",
    "The diffractometer software is able to collect patterns from 1 to  999, \n",
    "after which it will stop the acquisition. However, the experiment might be \n",
    "continued. The acquired data will then be saved to another `.raw` file.\n",
    "The 'deadtime' between experiments can be calculated and the aforementioned\n",
    "acquisition/exposure time is used to calculate the number of empty scans to use\n",
    "in an overview plot. Dummy scans will be written to a folder called \n",
    "`data_dummy`.\n",
    "\n",
    "A scaled background will be subtracted from all of the data files. The scale \n",
    "factor used will be the common maximum scale factor, which results in no \n",
    "negative intensities after the background subtraction. The scale factor used \n",
    "will be written to a file called `scale.txt`.\n",
    "\n",
    "The background-subtracted files and the dummy scans will be copied to a folder\n",
    "called `data_all`. Files to plot will be read from this directory, so the order\n",
    "of files plotted can be inspected in this folder.\n",
    "\n",
    "A matrix containing the x-array (*Q*-values) in the first column and the y \n",
    "values (intensities) in the subsequent columns are written to `.npy` and `.csv` \n",
    "files that are saved to folders called `npy` and `csv`, respectively. The user \n",
    "can use these files, e.g., for subsequent plotting, e.g., in Python (`.npy`) and\n",
    "Origin (`.csv`).\n",
    "\n",
    "Finally, an overview plot with the time, *t*, in hours, h, on the horizontal \n",
    "axis, the momentum transfer, *Q*, in inverse Ångström, Å^-1, and the intensity, \n",
    "*I*, in arbitrary units, arb. u., given by the color contour is written to \n",
    "`.png`, `.pdf`, and `.svg` files, in the created `png`, `pdf`, and `svg` \n",
    "folders, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary with plot settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_PLOT = dict(dpi=600,\n",
    "              figsize=(8, 6),\n",
    "              cmap=\"viridis\",\n",
    "              cmap_bad=\"white\",\n",
    "              aspect=\"auto\",\n",
    "              interpolation=\"antialiased\",\n",
    "              origin=\"upper\",\n",
    "              vmax_scale=2.5,\n",
    "              fontsize_labels=20,\n",
    "              fontsize_ticks=14,\n",
    "              pad_labels=10,\n",
    "              tick_width_major=1.5,\n",
    "              tick_width_minor=0.75,\n",
    "              xlabel=\"$t\\;[\\mathrm{h}]$\",\n",
    "              ylabel=\"$Q\\;[\\mathrm{\\AA}^{-1}]$\",\n",
    "              cbarlabel=\"$I\\;[\\mathrm{arb. u.}]$\",\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times(raw):\n",
    "    with raw.open(\"rb\") as f:\n",
    "        rb = f.read()\n",
    "    s = str(rb).split(\"\\\\x00\")\n",
    "    s = [e for e in s if not e == \"\"][1]\n",
    "    s = f\"{s[0:7]}20{s[7:]}\"\n",
    "    dt= datetime.strptime(s,\"%d-%b-%Y %H:%M\")\n",
    "    timestamp = dt.timestamp()\n",
    "    mtime = raw.stat().st_mtime\n",
    "    \n",
    "    return timestamp, mtime\n",
    "\n",
    "\n",
    "def get_exposure_time(raw):\n",
    "    with raw.open(\"rb\") as f:\n",
    "        rb = f.read()\n",
    "    s = str(rb).split(\"\\\\x00\")\n",
    "    s = [e for e in s if not e == \"\"][4].split()[-1]\n",
    "    value_list, unit_list = re.findall(\"\\d\", s), re.findall(\"\\D\", s)\n",
    "    value, unit = \"\", \"\"\n",
    "    for e in value_list:\n",
    "        value += e\n",
    "    for e in unit_list:\n",
    "        unit += e\n",
    "    if unit == \"min\":\n",
    "        value = float(value) * 60\n",
    "    elif unit == \"h\":\n",
    "        value = float(value) * 60**2\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def xy_to_dict(xy):\n",
    "    data = np.loadtxt(xy)\n",
    "\n",
    "    return dict(x=data[:, 0], y=data[:, 1])\n",
    "\n",
    "\n",
    "def xy_scale(y, y_bkg, oom):\n",
    "    scale = 1\n",
    "    y_diff = y - (scale * y_bkg)\n",
    "    if (y_diff >= 0).all():\n",
    "        upscale = True\n",
    "        downscale = False\n",
    "    else:\n",
    "        upscale = False\n",
    "        downscale = True\n",
    "    while upscale:\n",
    "        scale += oom\n",
    "        y_diff = y - (scale * y_bkg)\n",
    "        if (y_diff >= 0).all():\n",
    "            upscale = True\n",
    "        else:\n",
    "            upscale = False\n",
    "            scale -= oom\n",
    "    while downscale:\n",
    "        scale -= oom\n",
    "        y_diff = y - (scale * y_bkg)\n",
    "        if (y_diff < 0).any():\n",
    "            downscale = True\n",
    "        else:\n",
    "            downscale = False\n",
    "\n",
    "    return scale\n",
    "\n",
    "\n",
    "def dict_to_array(d):\n",
    "    for i, k in enumerate(list(d.keys())):\n",
    "        if i == 0:\n",
    "            array = np.column_stack((d[k][\"x\"], d[k][\"y\"]))\n",
    "        else:\n",
    "            array = np.column_stack((array, d[k][\"y\"]))\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "def plot(array, duration_h, d_plot, basename, output_paths):\n",
    "    x, y = array[:, 0], array[:, 1:]\n",
    "    y_masked = np.ma.masked_where(y < 0, y)\n",
    "    cmap = colormaps[d_plot[\"cmap\"]].set_bad(color=d_plot[\"cmap_bad\"])\n",
    "    fig, ax = plt.subplots(dpi=600, figsize=(12, 5))\n",
    "    im = ax.imshow(y_masked,\n",
    "                   cmap=cmap,\n",
    "                   interpolation=d_plot[\"interpolation\"],\n",
    "                   aspect=d_plot[\"aspect\"],\n",
    "                   origin=d_plot[\"origin\"],\n",
    "                   vmin=0,\n",
    "                   vmax=np.amax(y) / d_plot[\"vmax_scale\"],\n",
    "                   extent=(0, duration_h, np.amax(x), np.amin(x)),\n",
    "                   )\n",
    "    ax.tick_params(axis=\"x\",\n",
    "                   which=\"major\",\n",
    "                   bottom=True,\n",
    "                   labelbottom=False,\n",
    "                   top=True,\n",
    "                   labeltop=True,\n",
    "                   direction=\"in\",\n",
    "                   labelsize=d_plot[\"fontsize_ticks\"],\n",
    "                   width=d_plot[\"tick_width_major\"],\n",
    "                   )\n",
    "    ax.tick_params(axis=\"x\",\n",
    "                   which=\"minor\",\n",
    "                   bottom=True,\n",
    "                   labelbottom=False,\n",
    "                   top=True,\n",
    "                   labeltop=True,\n",
    "                   direction=\"in\",\n",
    "                   width=d_plot[\"tick_width_minor\"],\n",
    "                   )\n",
    "    ax.tick_params(axis=\"y\",\n",
    "                   which=\"major\",\n",
    "                   right=True,\n",
    "                   labelright=False,\n",
    "                   left=True,\n",
    "                   labelleft=True,\n",
    "                   direction=\"in\",\n",
    "                   labelsize=d_plot[\"fontsize_ticks\"],\n",
    "                   width=d_plot[\"tick_width_major\"],\n",
    "                   )\n",
    "    ax.tick_params(axis=\"y\",\n",
    "                   which=\"minor\",\n",
    "                   right=True,\n",
    "                   labelright=False,\n",
    "                   left=True,\n",
    "                   labelleft=True,\n",
    "                   direction=\"in\",\n",
    "                   width=d_plot[\"tick_width_minor\"],\n",
    "                   )    \n",
    "    ax.minorticks_on()\n",
    "    ax.set_xlabel(d_plot[\"xlabel\"],\n",
    "                  fontsize=d_plot[\"fontsize_labels\"],\n",
    "                  labelpad=d_plot[\"pad_labels\"],\n",
    "                  )\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.set_ylabel(d_plot[\"ylabel\"],\n",
    "                  fontsize=d_plot[\"fontsize_labels\"],\n",
    "                  labelpad=d_plot[\"pad_labels\"],\n",
    "                  )\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(d_plot[\"cbarlabel\"],\n",
    "                   fontsize=d_plot[\"fontsize_labels\"],\n",
    "                   labelpad=d_plot[\"pad_labels\"],\n",
    "                   )\n",
    "    cbar.formatter.set_powerlimits((0, 0))\n",
    "    for p in output_paths:\n",
    "        print(f\"\\t{p.name}\")\n",
    "        plt.savefig(p / f\"{basename}.{p.name}\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"data\"\n",
    "if not data_path.exists():\n",
    "    data_path.mkdir()\n",
    "    sys.exit(f\"\\n{80*'-'}\\nA folder called '{data_path.name}' has been \"\n",
    "             f\"created.\\nPlease place your data files there and rerun the \"\n",
    "             f\"cell.\\n{80*'-'}\"\n",
    "             )    \n",
    "data_files = list(data_path.glob(\"*.*\"))\n",
    "if len(data_files) == 0:\n",
    "    sys.exit(f\"\\n{80*'-'}\\nNo files were found in the '{data_path.name}' \"\n",
    "             f\"folder.\\nPlease place your data files there and rerun the \"\n",
    "             f\"cell.\\n{80*'-'}\"\n",
    "             )\n",
    "data_ext = []\n",
    "for e in data_files:\n",
    "    if e.suffix not in data_ext:\n",
    "        data_ext.append(e.suffix)\n",
    "if len(data_ext) > 1:\n",
    "    sys.exit(f\"\\n{80*'-'}\\n{len(data_ext)} different file extensions \"\n",
    "             f\"{data_ext} were found in the '{data_path.name}' folder.\"\n",
    "             f\"\\nPlease ensure that only one file extension is present in \"\n",
    "             f\"the '{data_path.name}' folder and\\nrerun the cell.\"\n",
    "             f\"\\n{80*'-'}\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting background file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_path = Path.cwd() / \"bkg\"\n",
    "if not bkg_path.exists():\n",
    "    bkg_path.mkdir()\n",
    "    sys.exit(f\"\\n{80*'-'}\\nA folder called '{bkg_path.name}' has been \"\n",
    "             f\"created.\\nPlease place your background file there and rerun \"\n",
    "             f\"the cell.\\n{80*'-'}\"\n",
    "             )\n",
    "bkg_files = list(bkg_path.glob(\"*.*\"))\n",
    "if len(bkg_files) == 0:\n",
    "    sys.exit(f\"\\n{80*'-'}\\nNo background file was found in the \"\n",
    "             f\"'{bkg_path.name}' folder.\\nPlease put the background file \"\n",
    "             f\"in the '{bkg_path.name}' folder and rerun the cell.\"\n",
    "             f\"\\n{80*'-'}\"\n",
    "             )\n",
    "if len(bkg_files) > 1:\n",
    "    sys.exit(f\"\\n{80*'-'}\\nMore than one file was found in the \"\n",
    "             f\"'{bkg_path.name}' folder.\\nPlease ensure that only one file \"\n",
    "             f\"is present in the '{bkg_path.name}' folder and rerun the\\n\"\n",
    "             f\"cell.\\n{80*'-'}\"\n",
    "             )\n",
    "bkg_file = bkg_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing `.raw` files.  \n",
    "Reading exposure time from the first `.raw` file and reading the time of last\n",
    "modification for each `.raw` file.  \n",
    "Calculating the duration of each (sub)experiment, the deadtime time between \n",
    "experiments and the corresponding number of dummy (blank) scans, and the total \n",
    "duration of the experiment(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Exposure time:\t\t\t300.0 s\n",
      "--------------------------------------------------------------------------------\n",
      "Duration of experiment 1:\t85.15 h\n",
      "\t\t\t\t3.55 days\n",
      "--------------------------------------------------------------------------------\n",
      "Duration of experiment 2:\t70.01 h\n",
      "\t\t\t\t2.92 days\n",
      "--------------------------------------------------------------------------------\n",
      "Total duration:\t\t\t162.52 h\n",
      "\t\t\t\t6.77 days\n",
      "--------------------------------------------------------------------------------\n",
      "Deadtime between exp. 1 and 2:\t7.36 h\n",
      "\t\t\t\t0.31 days\n",
      "Number of empty scans:\t\t88 scans\n"
     ]
    }
   ],
   "source": [
    "raw_path = Path.cwd() / \"raw\"\n",
    "if not raw_path.exists():\n",
    "    raw_path.mkdir()\n",
    "    sys.exit(f\"\\n{80*'-'}\\nA folder called '{raw_path.name}' has been \"\n",
    "             f\"created.\\nPlease place your .raw file(s) there and rerun \"\n",
    "             f\"the cell.\\n{80*'-'}\"\n",
    "             )    \n",
    "raw_files = list(raw_path.glob(\"*.*\"))\n",
    "if len(raw_files) == 0:\n",
    "    sys.exit(f\"\\n{80*'-'}\\nNo files were found in the '{raw_path.name}' \"\n",
    "             f\"folder.\\nPlease place your .raw file(s) there and rerun the \"\n",
    "             f\"cell.\\n{80*'-'}\"\n",
    "             )\n",
    "timestamps, mtimes, durations = [], [], []\n",
    "for i, raw in enumerate(raw_files):\n",
    "    if i == 0:\n",
    "        exp_time = get_exposure_time(raw)\n",
    "        print(f\"{80*'-'}\\nExposure time:\\t\\t\\t{exp_time} s\")\n",
    "    timestamp, mtime = get_times(raw)\n",
    "    timestamps.append(timestamp)\n",
    "    mtimes.append(mtime)\n",
    "    durations.append(mtimes[-1] - timestamps[-1])\n",
    "    print(f\"{80*'-'}\\nDuration of experiment {i+1}:\"\n",
    "            f\"\\t{durations[-1] / 60**2:.2f} h\"\n",
    "            f\"\\n\\t\\t\\t\\t{durations[-1] / (60**2 * 24):.2f} days\"\n",
    "            )\n",
    "    if i == 0:\n",
    "        start = timestamps[-1]\n",
    "    elif i == len(raw_files) - 1:\n",
    "        end = mtimes[-1]\n",
    "duration = end - start\n",
    "print(f\"{80*'-'}\\nTotal duration:\\t\\t\\t{duration / 60**2:.2f} h\"\n",
    "        f\"\\n\\t\\t\\t\\t{duration / (60**2 * 24):.2f} days\"\n",
    "        )\n",
    "for i in range(1, len(durations)):\n",
    "    deadtime = timestamps[i] - mtimes[i-1]\n",
    "    n_dummies = int(deadtime / exp_time)\n",
    "    print(f\"{80*'-'}\\nDeadtime between exp. {i} and {i+1}:\"\n",
    "        f\"\\t{deadtime / 60**2:.2f} h\"\n",
    "        f\"\\n\\t\\t\\t\\t{deadtime / (60**2 * 24):.2f} days\"\n",
    "        f\"\\nNumber of empty scans:\\t\\t{n_dummies} scans\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing dummy scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Dummy scan template: 20230126_JKV_LFPvsLitynd.001.xy\n",
      "--------------------------------------------------------------------------------\n",
      "Writing dummy scans to the 'data_dummy' folder....\n",
      "Done.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dummy_template = data_files[0]\n",
    "data_dummy_path = Path.cwd() / \"data_dummy\"\n",
    "if not data_dummy_path.exists():\n",
    "    data_dummy_path.mkdir()\n",
    "print(f\"{80*'-'}\\nDummy scan template: {dummy_template.name}\\n{80*'-'}\"\n",
    "      f\"\\nWriting dummy scans to the '{data_dummy_path.name}' folder....\"\n",
    "      )\n",
    "x = np.loadtxt(dummy_template)[:, 0]\n",
    "y = np.zeros_like(x) - 1\n",
    "for i in range(1, len(durations)):\n",
    "    for j in range(n_dummies):\n",
    "        fname = dummy_template.stem.split(\".\")\n",
    "        fname = f\"{fname[0]}_{i}.1{str(j).zfill(3)}\"\n",
    "        fname += f\"{dummy_template.suffix}\"\n",
    "        output_path = data_dummy_path / fname\n",
    "        np.savetxt(output_path,\n",
    "                    np.column_stack((x, y)),\n",
    "                    delimiter=\"\\t\",\n",
    "                    fmt=\"%.8f\\t%i\",\n",
    "                    encoding=\"utf-8\",\n",
    "                    )\n",
    "print(f\"Done.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i, e in enumerate(data_files):\n",
    "    d[i] = xy_to_dict(e)\n",
    "d_bkg = xy_to_dict(bkg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining scale factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Maximum scale factor value for no negative intensities: 0.767\n",
      "Scale factor written to scale.txt file.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scales = []\n",
    "scans = list(d.keys())\n",
    "oom = 10**-3\n",
    "for scan in scans:\n",
    "    scales.append(xy_scale(d[scan][\"y\"], d_bkg[\"y\"], oom))\n",
    "scale = np.amin(np.array(scales))\n",
    "scale_str = f\"{scale:.3f}\"\n",
    "print(f\"{80*'-'}\\nMaximum scale factor value for no negative intensities: \"\n",
    "      f\"{scale_str}\"\n",
    "      )\n",
    "scale_path = Path.cwd() / \"scale.txt\"\n",
    "with scale_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(scale_str)\n",
    "print(f\"Scale factor written to {scale_path.name} file.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Writing background-subtracted files to the 'data_bkg-sub' folder...\n",
      "Done.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_bkg_sub_path = Path.cwd() / \"data_bkg-sub\"\n",
    "if not data_bkg_sub_path.exists():\n",
    "    data_bkg_sub_path.mkdir()\n",
    "print(f\"{80*'-'}\\nWriting background-subtracted files to the \"\n",
    "      f\"'{data_bkg_sub_path.name}' folder...\"\n",
    "      )\n",
    "for scan in scans:\n",
    "    d[scan][\"y_bkg_sub\"] = d[scan][\"y\"] - (scale * d_bkg[\"y\"])\n",
    "    np.savetxt(data_bkg_sub_path / data_files[scan].name,\n",
    "               np.column_stack((d[scan][\"x\"], d[scan][\"y_bkg_sub\"])),\n",
    "               delimiter=\"\\t\",\n",
    "               fmt=\"%.8f\\t%.1f\",\n",
    "               encoding=\"utf-8\",\n",
    "               )\n",
    "print(f\"Done.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying all data files and dummy scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Copying background-subtracted files and dummy files to the 'data_all' folder...\n",
      "Done.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_all_path = Path.cwd() / \"data_all\"\n",
    "data_bkg_sub_files = list(data_bkg_sub_path.glob(\"*.*\"))\n",
    "data_dummy_files = list(data_dummy_path.glob(\"*.*\"))\n",
    "if not data_all_path.exists():\n",
    "    data_all_path.mkdir()\n",
    "print(f\"{80*'-'}\\nCopying background-subtracted files and dummy files to \"\n",
    "      f\"the '{data_all_path.name}' folder...\"\n",
    "      )\n",
    "for f in data_bkg_sub_files:\n",
    "    (data_all_path / f.name).write_text(f.read_text())\n",
    "for f in data_dummy_files:\n",
    "    (data_all_path / f.name).write_text(f.read_text())\n",
    "print(f\"Done.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating matrix and writing to `.npy` and `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Creating matrix...\n",
      "Done.\n",
      "--------------------------------------------------------------------------------\n",
      "Writing to .npy file...\n",
      "Done. Please see the 'npy' folder.\n",
      "--------------------------------------------------------------------------------\n",
      "Writing to .csv file...\n",
      "Done. Please see the 'csv' folder.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{80*'-'}\\nCreating matrix...\")\n",
    "data_all_files = list(data_all_path.glob(\"*.*\"))\n",
    "d = {}\n",
    "for i, e in enumerate(data_all_files):\n",
    "    d[i] = xy_to_dict(e)\n",
    "array = dict_to_array(d)\n",
    "print(f\"Done.\\n{80*'-'}\\nWriting to .npy file...\")\n",
    "basename = data_all_files[0].stem.split(\".\")[0]\n",
    "npy_path = Path.cwd() / \"npy\"\n",
    "if not npy_path.exists():\n",
    "    npy_path.mkdir()\n",
    "np.save(npy_path / basename, array)\n",
    "print(f\"Done. Please see the '{npy_path.name}' folder.\\n{80*'-'}\\n\"\n",
    "      f\"Writing to .csv file...\"\n",
    "      )\n",
    "csv_path = Path.cwd() / \"csv\"\n",
    "if not csv_path.exists():\n",
    "    csv_path.mkdir()\n",
    "cols = [\"x\"]\n",
    "for e in range(len(data_all_files)):\n",
    "    cols.append(str(e))\n",
    "df = pd.DataFrame(array, columns=cols)\n",
    "df.to_csv(csv_path / f\"{basename}.csv\")\n",
    "print(f\"Done. Please see the '{csv_path.name}' folder.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x-ranges to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Minimum x-value in data: 0.78397238\n",
      "Maximum x-value in data: 7.02178907\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide the minimum x-value to plot:  1\n",
      "Please provide the maximum x-value to plot:  5\n"
     ]
    }
   ],
   "source": [
    "x = np.loadtxt(data_files[0])[:, 0]\n",
    "xmin, xmax = np.amin(x), np.amax(x)\n",
    "print(f\"{80*'-'}\\nMinimum x-value in data: {xmin}\"\n",
    "      f\"\\nMaximum x-value in data: {xmax}\\n{80*'-'}\"\n",
    "      )\n",
    "xmin = float(input(f\"Please provide the minimum x-value to plot: \"))\n",
    "xmax = float(input(f\"Please provide the maximum x-value to plot: \"))\n",
    "xmin_index, xmax_index = 0, -1\n",
    "for i in range(len(x)):\n",
    "    if xmin <= x[i]:\n",
    "        xmin_index = i\n",
    "        break\n",
    "for i in range(len(x)):\n",
    "    if xmax <= x[i]:\n",
    "        xmax_index = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Plotting...\n",
      "\tpng\n",
      "\tpdf\n",
      "\tsvg\n",
      "Done. Please see the ['png', 'pdf', 'svg'] folders.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{80*'-'}\\nPlotting...\")\n",
    "png_path, pdf_path = Path.cwd() / \"png\", Path.cwd() / \"pdf\"\n",
    "svg_path = Path.cwd() / \"svg\"\n",
    "plot_paths = [png_path, pdf_path, svg_path]\n",
    "plot_folders = [p.name for p in plot_paths]\n",
    "for p in plot_paths:\n",
    "    if not p.exists():\n",
    "        p.mkdir()\n",
    "plot(array[xmin_index:xmax_index+1, :], \n",
    "     duration / 60**2, \n",
    "     D_PLOT, \n",
    "     basename, \n",
    "     plot_paths,\n",
    "     )\n",
    "print(f\"Done. Please see the {plot_folders} folders.\\n{80*'-'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
